{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387d21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c81805",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corpus = '''These are the Terms and Conditions governing the use of this Service and the agreement \n",
    "that operates between You and the Company. These Terms and Conditions set out the rights and obligations of \n",
    "all users regarding the use of the Service. Your access to and use of the Service is conditioned on Your \n",
    "acceptance of and compliance with these Terms and Conditions. These Terms and Conditions apply to all visitors, \n",
    "users and others who access or use the Service. By accessing or using the Service You agree to be bound by these \n",
    "Terms and Conditions. If You disagree with any part of these Terms and Conditions then You may not access the Service. \n",
    "You represent that you are over the age of 18. The Company does not permit those under 18 to use the Service. \n",
    "Your access to and use of the Service is also conditioned on Your acceptance of and compliance with the Privacy Policy \n",
    "of the Company. Our Privacy Policy describes Our policies and procedures on the collection, use and disclosure of \n",
    "Your personal information when You use the Application or the Website and tells You about Your privacy rights and \n",
    "how the law protects You. Please read Our Privacy Policy carefully before using Our Service. Intellectual Property \n",
    "The Service and its original content (excluding Content provided by You or other users), features and functionality \n",
    "are and will remain the exclusive property of the Company and its licensors. The Service is protected by copyright, \n",
    "trademark, and other laws of both the Country and foreign countries. Our trademarks and trade dress may not be \n",
    "used in connection with any product or service without the prior written consent of the Company.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d93de8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to k:\\NLP\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to k:\\NLP\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to k:\\NLP\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokenize --> para to sentense \n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# Optional: clear existing nltk_data (if corrupted)\n",
    "nltk.data.path.clear()\n",
    "\n",
    "# Force path to a clean directory\n",
    "nltk_data_path = os.path.abspath('nltk_data')\n",
    "nltk.download('punkt_tab', download_dir=nltk_data_path)\n",
    "nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "nltk.data.path.append(nltk_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8b653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = nltk.sent_tokenize(corpus, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bc9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.data.path.append(os.path.abspath('./nltk_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7fb1085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['These are the Terms and Conditions governing the use of this Service and the agreement \\nthat operates between You and the Company.',\n",
       " 'These Terms and Conditions set out the rights and obligations of \\nall users regarding the use of the Service.',\n",
       " 'Your access to and use of the Service is conditioned on Your \\nacceptance of and compliance with these Terms and Conditions.',\n",
       " 'These Terms and Conditions apply to all visitors, \\nusers and others who access or use the Service.',\n",
       " 'By accessing or using the Service You agree to be bound by these \\nTerms and Conditions.',\n",
       " 'If You disagree with any part of these Terms and Conditions then You may not access the Service.',\n",
       " 'You represent that you are over the age of 18.',\n",
       " 'The Company does not permit those under 18 to use the Service.',\n",
       " 'Your access to and use of the Service is also conditioned on Your acceptance of and compliance with the Privacy Policy \\nof the Company.',\n",
       " 'Our Privacy Policy describes Our policies and procedures on the collection, use and disclosure of \\nYour personal information when You use the Application or the Website and tells You about Your privacy rights and \\nhow the law protects You.',\n",
       " 'Please read Our Privacy Policy carefully before using Our Service.',\n",
       " 'Intellectual Property \\nThe Service and its original content (excluding Content provided by You or other users), features and functionality \\nare and will remain the exclusive property of the Company and its licensors.',\n",
       " 'The Service is protected by copyright, \\ntrademark, and other laws of both the Country and foreign countries.',\n",
       " 'Our trademarks and trade dress may not be \\nused in connection with any product or service without the prior written consent of the Company.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a33d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming - reducing words to its base root word\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2eb2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmetization -- more accuracy breaking of sentences into base root words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemme = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae992ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c680e715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemme.lemmatize('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e461a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cleaned_corpus =[]\n",
    "for i in range(len(documents)):\n",
    "    review = re.sub('[^a-zA-Z]',' ', documents[i])\n",
    "    review = review.lower()\n",
    "    cleaned_corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a759a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['these are the terms and conditions governing the use of this service and the agreement  that operates between you and the company ',\n",
       " 'these terms and conditions set out the rights and obligations of  all users regarding the use of the service ',\n",
       " 'your access to and use of the service is conditioned on your  acceptance of and compliance with these terms and conditions ',\n",
       " 'these terms and conditions apply to all visitors   users and others who access or use the service ',\n",
       " 'by accessing or using the service you agree to be bound by these  terms and conditions ',\n",
       " 'if you disagree with any part of these terms and conditions then you may not access the service ',\n",
       " 'you represent that you are over the age of    ',\n",
       " 'the company does not permit those under    to use the service ',\n",
       " 'your access to and use of the service is also conditioned on your acceptance of and compliance with the privacy policy  of the company ',\n",
       " 'our privacy policy describes our policies and procedures on the collection  use and disclosure of  your personal information when you use the application or the website and tells you about your privacy rights and  how the law protects you ',\n",
       " 'please read our privacy policy carefully before using our service ',\n",
       " 'intellectual property  the service and its original content  excluding content provided by you or other users   features and functionality  are and will remain the exclusive property of the company and its licensors ',\n",
       " 'the service is protected by copyright   trademark  and other laws of both the country and foreign countries ',\n",
       " 'our trademarks and trade dress may not be  used in connection with any product or service without the prior written consent of the company ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699d3ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "condit\n",
      "govern\n",
      "use\n",
      "servic\n",
      "agreement\n",
      "oper\n",
      "compani\n",
      "term\n",
      "condit\n",
      "set\n",
      "right\n",
      "oblig\n",
      "user\n",
      "regard\n",
      "use\n",
      "servic\n",
      "access\n",
      "use\n",
      "servic\n",
      "condit\n",
      "accept\n",
      "complianc\n",
      "term\n",
      "condit\n",
      "term\n",
      "condit\n",
      "appli\n",
      "visitor\n",
      "user\n",
      "other\n",
      "access\n",
      "use\n",
      "servic\n",
      "access\n",
      "use\n",
      "servic\n",
      "agre\n",
      "bound\n",
      "term\n",
      "condit\n",
      "disagre\n",
      "part\n",
      "term\n",
      "condit\n",
      "may\n",
      "access\n",
      "servic\n",
      "repres\n",
      "age\n",
      "compani\n",
      "permit\n",
      "use\n",
      "servic\n",
      "access\n",
      "use\n",
      "servic\n",
      "also\n",
      "condit\n",
      "accept\n",
      "complianc\n",
      "privaci\n",
      "polici\n",
      "compani\n",
      "privaci\n",
      "polici\n",
      "describ\n",
      "polici\n",
      "procedur\n",
      "collect\n",
      "use\n",
      "disclosur\n",
      "person\n",
      "inform\n",
      "use\n",
      "applic\n",
      "websit\n",
      "tell\n",
      "privaci\n",
      "right\n",
      "law\n",
      "protect\n",
      "pleas\n",
      "read\n",
      "privaci\n",
      "polici\n",
      "care\n",
      "use\n",
      "servic\n",
      "intellectu\n",
      "properti\n",
      "servic\n",
      "origin\n",
      "content\n",
      "exclud\n",
      "content\n",
      "provid\n",
      "user\n",
      "featur\n",
      "function\n",
      "remain\n",
      "exclus\n",
      "properti\n",
      "compani\n",
      "licensor\n",
      "servic\n",
      "protect\n",
      "copyright\n",
      "trademark\n",
      "law\n",
      "countri\n",
      "foreign\n",
      "countri\n",
      "trademark\n",
      "trade\n",
      "dress\n",
      "may\n",
      "use\n",
      "connect\n",
      "product\n",
      "servic\n",
      "without\n",
      "prior\n",
      "written\n",
      "consent\n",
      "compani\n"
     ]
    }
   ],
   "source": [
    "for i in cleaned_corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "634e23ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "condition\n",
      "governing\n",
      "use\n",
      "service\n",
      "agreement\n",
      "operates\n",
      "company\n",
      "term\n",
      "condition\n",
      "set\n",
      "right\n",
      "obligation\n",
      "user\n",
      "regarding\n",
      "use\n",
      "service\n",
      "access\n",
      "use\n",
      "service\n",
      "conditioned\n",
      "acceptance\n",
      "compliance\n",
      "term\n",
      "condition\n",
      "term\n",
      "condition\n",
      "apply\n",
      "visitor\n",
      "user\n",
      "others\n",
      "access\n",
      "use\n",
      "service\n",
      "accessing\n",
      "using\n",
      "service\n",
      "agree\n",
      "bound\n",
      "term\n",
      "condition\n",
      "disagree\n",
      "part\n",
      "term\n",
      "condition\n",
      "may\n",
      "access\n",
      "service\n",
      "represent\n",
      "age\n",
      "company\n",
      "permit\n",
      "use\n",
      "service\n",
      "access\n",
      "use\n",
      "service\n",
      "also\n",
      "conditioned\n",
      "acceptance\n",
      "compliance\n",
      "privacy\n",
      "policy\n",
      "company\n",
      "privacy\n",
      "policy\n",
      "describes\n",
      "policy\n",
      "procedure\n",
      "collection\n",
      "use\n",
      "disclosure\n",
      "personal\n",
      "information\n",
      "use\n",
      "application\n",
      "website\n",
      "tell\n",
      "privacy\n",
      "right\n",
      "law\n",
      "protects\n",
      "please\n",
      "read\n",
      "privacy\n",
      "policy\n",
      "carefully\n",
      "using\n",
      "service\n",
      "intellectual\n",
      "property\n",
      "service\n",
      "original\n",
      "content\n",
      "excluding\n",
      "content\n",
      "provided\n",
      "user\n",
      "feature\n",
      "functionality\n",
      "remain\n",
      "exclusive\n",
      "property\n",
      "company\n",
      "licensors\n",
      "service\n",
      "protected\n",
      "copyright\n",
      "trademark\n",
      "law\n",
      "country\n",
      "foreign\n",
      "country\n",
      "trademark\n",
      "trade\n",
      "dress\n",
      "may\n",
      "used\n",
      "connection\n",
      "product\n",
      "service\n",
      "without\n",
      "prior\n",
      "written\n",
      "consent\n",
      "company\n"
     ]
    }
   ],
   "source": [
    "for i in cleaned_corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemme.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e45bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwrod lemmetize \n",
    "for i in range(len(documents)):\n",
    "    review = re.sub('[^A-Za-z]',' ', documents[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemme.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    cleaned_corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cea066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary= True, ngram_range=(2,3), max_features= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fa804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv.fit_transform(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66d44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the service': np.int64(0), 'use service': np.int64(1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e32ffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notes : REMOVE STOPWORDS\\nTURN PARAS INTO SENTENCE \\nGET FREQUENCY OF VOCABS'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''Notes : REMOVE STOPWORDS\n",
    "TURN PARAS INTO SENTENCE \n",
    "GET FREQUENCY OF VOCABS'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b20c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TFIDF - term freq inverse document freq\\ntf = no of repetitions of a word in a sentence/ total words in a sentence\\nidf = log(no of sentence/ no of sentence with that specific word) \\n\\ntf*idf\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''TFIDF - term freq inverse document freq\n",
    "tf = no of repetitions of a word in a sentence/ total words in a sentence\n",
    "idf = log(no of sentence/ no of sentence with that specific word) \n",
    "\n",
    "tf*idf\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fddafbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "\n",
    "y = cv.fit_transform(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60110c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''experimenting with a data set'''\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/clean_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8d47733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>source</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>work_type</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Meta</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Social Measurement team is a growing team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Data Analyst II</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>About Pinterest\\n\\nMillions of people around t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            title    company           location  \\\n",
       "0   1     Data Analyst       Meta       New York, NY   \n",
       "1   2     Data Analyst       Meta  San Francisco, CA   \n",
       "2   3     Data Analyst       Meta    Los Angeles, CA   \n",
       "3   4     Data Analyst       Meta     Washington, DC   \n",
       "4   5  Data Analyst II  Pinterest        Chicago, IL   \n",
       "\n",
       "                                                link    source date_posted  \\\n",
       "0  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "1  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "2  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "3  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-16   \n",
       "\n",
       "   work_type  employment_type  \\\n",
       "0        NaN              NaN   \n",
       "1        NaN              NaN   \n",
       "2        NaN              NaN   \n",
       "3        NaN              NaN   \n",
       "4        NaN              NaN   \n",
       "\n",
       "                                         description  \n",
       "0  The Social Measurement team is a growing team ...  \n",
       "1  The Social Measurement team is a growing team ...  \n",
       "2  The Social Measurement team is a growing team ...  \n",
       "3  The Social Measurement team is a growing team ...  \n",
       "4  About Pinterest\\n\\nMillions of people around t...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfac2a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of       id                          title                 company  \\\n",
       "0      1                   Data Analyst                    Meta   \n",
       "1      2                   Data Analyst                    Meta   \n",
       "2      3                   Data Analyst                    Meta   \n",
       "3      4                   Data Analyst                    Meta   \n",
       "4      5                Data Analyst II               Pinterest   \n",
       "..   ...                            ...                     ...   \n",
       "322  691  Data Engineer- Python Pyspark                 Virtusa   \n",
       "323  692     Data Engineer with Pyspark               Cognizant   \n",
       "324  693                  Data Engineer  Mercedes-Benz Malaysia   \n",
       "325  740                Data Engineer I                IntePros   \n",
       "326  741                  Data Engineer               Snap Inc.   \n",
       "\n",
       "                              location  \\\n",
       "0                         New York, NY   \n",
       "1                    San Francisco, CA   \n",
       "2                      Los Angeles, CA   \n",
       "3                       Washington, DC   \n",
       "4                          Chicago, IL   \n",
       "..                                 ...   \n",
       "322         Chennai, Tamil Nadu, India   \n",
       "323  Bangalore Urban, Karnataka, India   \n",
       "324        Puchong, Selangor, Malaysia   \n",
       "325                        Seattle, WA   \n",
       "326                       Bellevue, WA   \n",
       "\n",
       "                                                  link    source date_posted  \\\n",
       "0    https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "1    https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "2    https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "3    https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-14   \n",
       "4    https://www.linkedin.com/jobs/view/data-analys...  LinkedIn  2025-04-16   \n",
       "..                                                 ...       ...         ...   \n",
       "322  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-10   \n",
       "323  https://in.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-13   \n",
       "324  https://my.linkedin.com/jobs/view/data-enginee...  LinkedIn  2025-04-16   \n",
       "325  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-15   \n",
       "326  https://www.linkedin.com/jobs/view/data-engine...  LinkedIn  2025-04-16   \n",
       "\n",
       "     work_type  employment_type  \\\n",
       "0          NaN              NaN   \n",
       "1          NaN              NaN   \n",
       "2          NaN              NaN   \n",
       "3          NaN              NaN   \n",
       "4          NaN              NaN   \n",
       "..         ...              ...   \n",
       "322        NaN              NaN   \n",
       "323        NaN              NaN   \n",
       "324        NaN              NaN   \n",
       "325        NaN              NaN   \n",
       "326        NaN              NaN   \n",
       "\n",
       "                                           description  \n",
       "0    The Social Measurement team is a growing team ...  \n",
       "1    The Social Measurement team is a growing team ...  \n",
       "2    The Social Measurement team is a growing team ...  \n",
       "3    The Social Measurement team is a growing team ...  \n",
       "4    About Pinterest\\n\\nMillions of people around t...  \n",
       "..                                                 ...  \n",
       "322  Senior Data Engineer\\n\\nPosition Summary\\n\\nTh...  \n",
       "323  Job Title:- Data Engineer with Pyspark\\n\\nLoca...  \n",
       "324  About Us\\n\\n\\n\\n\\nAt Mercedes-Benz, we don’t j...  \n",
       "325  Data Engineer I – Infrastructure & Automation ...  \n",
       "326  Snap Inc is a technology company. We believe t...  \n",
       "\n",
       "[327 rows x 10 columns]>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b596ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Social Measurement team is a growing team ...\n",
       "1    The Social Measurement team is a growing team ...\n",
       "2    The Social Measurement team is a growing team ...\n",
       "3    The Social Measurement team is a growing team ...\n",
       "4    About Pinterest\\n\\nMillions of people around t...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['description']\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03fd9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^A-Za-z1-9]',' ',text)\n",
    "    text = text.lower().split()\n",
    "    text = [lemme.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]\n",
    "    return ' '.join(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bbfcdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus = corpus.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af8b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    social measurement team growing team high visi...\n",
       "1    social measurement team growing team high visi...\n",
       "2    social measurement team growing team high visi...\n",
       "3    social measurement team growing team high visi...\n",
       "4    pinterest million people around world come pla...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a617dd",
   "metadata": {},
   "source": [
    "BOW and TFIDF dont capture semantic meaning only capture the frequency of occurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10597ec7",
   "metadata": {},
   "source": [
    "Sparse Matrix created by BOW and TFIDF in simple words huge matrices like the one below this isnt pratical for huge datasets \n",
    "my dataset is in Megabytes and this matrix is for one column of that dataset then imagine terabytes of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3077be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23493031, 0.        , 0.        , 0.40587926,\n",
       "        0.        , 0.        , 0.        , 0.21425372, 0.        ,\n",
       "        0.        , 0.26407234, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14154686, 0.        , 0.        ,\n",
       "        0.        , 0.17403242, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23493031,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.14154686,\n",
       "        0.        , 0.23493031, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.08254047, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.17403242, 0.23493031, 0.49685521, 0.        , 0.17403242,\n",
       "        0.26407234, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11925507, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.17403242, 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc362bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
